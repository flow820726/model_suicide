{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "international-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import preprocessing\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn import tree\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# %run /home/jovyan/work/riskModel/a0001/copy_0822/DataPrepare.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "french-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_info(grid, m):\n",
    "    \"\"\"\n",
    "    取得 grid search info\n",
    "\n",
    "    :param grid: object, gird sarch\n",
    "    :param m: string, model name\n",
    "    :return: data.frame\n",
    "    \"\"\"\n",
    "\n",
    "    df_info = pd.DataFrame(grid.cv_results_)\n",
    "    df_info = df_info[['params', 'mean_test_score',\n",
    "                       'rank_test_score']]\n",
    "    df_info['model'] = m\n",
    "    return df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "intelligent-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(X, y, m=['tree', 'rf', 'adaboost', 'gbm'], m_params='', imbalance=False):\n",
    "    \"\"\"\n",
    "    select best model\n",
    "\n",
    "    :param X: data.frame/array, X\n",
    "    :param y: data.frame/array, y\n",
    "    :param m: list,, 待測試方法\n",
    "                    'tree': decision tree\n",
    "                    'rf': random forest\n",
    "                    'xgb': xgb\n",
    "    :return: model, cv result\n",
    "    \"\"\"\n",
    "\n",
    "    # model method\n",
    "    model_base = {\n",
    "\n",
    "        \"tree\": {\"model\": tree.DecisionTreeClassifier(),\n",
    "                 \"params\": {\"step1\": {'model__max_depth': [3, 5, 7]}}\n",
    "                 },\n",
    "\n",
    "        \"rf\": {\"model\": RandomForestClassifier(),\n",
    "               \"params\": {\"step1\": {'model__max_depth': [3, 5, 7]}}\n",
    "               },\n",
    "        \"adaboost\":{\"model\": AdaBoostClassifier(),\n",
    "                    \"params\": {\"step1\": {'model__n_estimators': [10, 30, 50],\n",
    "                                         'model__learning_rate': [ 0.01, 0.1, 1]}}\n",
    "               },\n",
    "        \"gbm\":{\"model\": GradientBoostingClassifier(random_state=0),\n",
    "               \"params\": {\"step1\": {'model__n_estimators': [10, 30, 50]},\n",
    "                          \"step2\": {'model__max_depth': [3, 5]}}\n",
    "               },\n",
    "        \"xgb\": {\"model\": XGBClassifier(colsample_bytree=0.8,\n",
    "                                       objective='binary:logistic',\n",
    "                                       scale_pos_weight=1,\n",
    "                                       eval_metric='error',\n",
    "                                       use_label_encoder=False),\n",
    "                \"params\": {'step1': {'model__max_depth': [3, 5, 7, 10],\n",
    "                                     'model__min_child_weight': [1e-1, 1, 1e1]},\n",
    "                           'step2': {'model__gamma': [0, 0.2]},\n",
    "                           'step3': {'model__subsample': [0.8, 0.9]},\n",
    "                           'step4': {'model__reg_alpha': [0, 1e-1, 1, 2]},\n",
    "                           'step5': {'model__learning_rate': [0.1, 1]}}\n",
    "                },\n",
    "        \"lgb\": {\"model\": lgb.LGBMClassifier(),\n",
    "                \"params\": {'step1': {'model__num_leaves': [5, 10, 20, 50]},\n",
    "                           'step2': {'model__min_child_weight': [1e-1, 1, 1e1]},\n",
    "                           'step3': {'model__subsample': [0.5, 0.8, 0.9, 1],\n",
    "                                     'model__colsample_bytree': [0.5, 0.8, 0.9, 1]},\n",
    "                           'step4': {'model__reg_alpha': [0, 1e-1, 1]}\n",
    "                           }\n",
    "                }\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # set params\n",
    "    if m_params == '':\n",
    "        model_params = {your_key: model_base[your_key][\n",
    "            'params'] for your_key in m}\n",
    "    else:\n",
    "        model_params = m_params\n",
    "\n",
    "    # balance adjust\n",
    "    if imbalance:\n",
    "        model_pipe = [\n",
    "            ('over', SMOTE(sampling_strategy=0.1)), ('under', RandomUnderSampler(sampling_strategy=0.5))]\n",
    "    else:\n",
    "        model_pipe = []\n",
    "    \n",
    "    md_dict, cv_result = {}, pd.DataFrame()\n",
    "    for i in m:\n",
    "        print(\"========== \" + i + \" Begin ==========\")\n",
    "        md = model_pipe + \\\n",
    "             [('model', model_base[i]['model'])]\n",
    "        pipeline = Pipeline(steps=md)\n",
    "\n",
    "        for step, param in model_params[i].items():\n",
    "            # start time\n",
    "            start = datetime.now()\n",
    "\n",
    "            # grid search\n",
    "            gs = GridSearchCV(estimator=pipeline,\n",
    "                              param_grid=param,\n",
    "                              scoring='roc_auc',\n",
    "                              cv=3)\n",
    "            gs.fit(X, y)\n",
    "            # end time\n",
    "            res = grid_info(gs, i)\n",
    "            t = datetime.now()-start\n",
    "            res['time'] = t\n",
    "            # save\n",
    "            cv_result = pd.concat([cv_result,\n",
    "                                   res])\n",
    "\n",
    "            # update\n",
    "            pipeline.set_params(**gs.best_params_)\n",
    "            print(step + \": \",\n",
    "                  gs.best_params_, \", time:\", t, \"==========\")\n",
    "\n",
    "        md_dict[i] = pipeline\n",
    "        print(i + \" Done ==========\")\n",
    "\n",
    "    # select best\n",
    "    cv_result.reset_index(drop=True, inplace=True)\n",
    "    best_score = cv_result['mean_test_score'].max()\n",
    "    best_res = cv_result[cv_result['mean_test_score'] == best_score]\n",
    "    best_md_name = best_res.loc[best_res['time'].idxmin(), 'model']\n",
    "\n",
    "    # fit best model\n",
    "    best_e = md_dict[best_md_name]\n",
    "    best_e.fit(X, y)\n",
    "    \n",
    "    # add all\n",
    "    res = pd.concat(\n",
    "        [cv_result,\n",
    "         pd.DataFrame({'params': [best_e.get_params()],\n",
    "                       'mean_test_score':[f1_score(y, best_e.predict(X), average='micro')],\n",
    "                       'rank_test_score':['all'],\n",
    "                       'model':[best_md_name]})])\n",
    "\n",
    "    return best_e, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "animal-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(est, X):\n",
    "    importances = est.get_params()['model'].feature_importances_\n",
    "    feature_names = X.columns\n",
    "    forest_importances = pd.Series(importances, index=feature_names)\n",
    "    forest_importances = forest_importances.sort_values(ascending=True)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    forest_importances.plot.barh()\n",
    "    ax.set_title(\"Feature importances\")\n",
    "    ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "hazardous-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(est, x, y):\n",
    "    # predict prob\n",
    "    yhat = est.predict_proba(x)\n",
    "    yhat = yhat[:, 1]\n",
    "    \n",
    "    # calculate roc\n",
    "    fpr, tpr, thresholds= roc_curve(y, yhat)\n",
    "    \n",
    "    # gmean\n",
    "    gmeans = np.sqrt(tpr * (1-fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    print(\"Best Threshold=%f, g-means=%.3f\" % (thresholds[ix], gmeans[ix]))\n",
    "    \n",
    "    # plot \n",
    "    plt.figure()\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.plot(fpr, tpr, marker='.', label='Model')\n",
    "    #plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "    plt.title('ROC Curve')\n",
    "    \n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.show\n",
    "    \n",
    "    # sum \n",
    "    \n",
    "    print('AUC:', auc(fpr, tpr))\n",
    "    return thresholds[ix]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "neural-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_info(y ,yhat):\n",
    "    cm = confusion_matrix(y, yhat)\n",
    "    print(cm)\n",
    "    tot = sum(sum(cm))\n",
    "    ac = (cm[0,0] + cm[1,1]) / tot\n",
    "    sen = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "    spe = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "    \n",
    "    print(\"Accuracy: \", ac,'\\n',\n",
    "          'Sensitivity: ', sen,'\\n',\n",
    "          'Specificity: ', spe,'\\n',\n",
    "          'Blance_Accuracy', (sen+spe)/2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "arabic-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_report(X, y, est):\n",
    "    y_pred = est.predict(X)\n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "reflected-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_process(train_x, train_y, test_x, test_y, m=['tree', 'rf', 'adaboost', 'gbm'], roc=True, m_params='', imbalance=False):\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [12, 6]\n",
    "    print(\"==================== Training Begin ====================\")\n",
    "    \n",
    "    # fit model\n",
    "    est, cv_report = best_model(train_x, train_y, m=m, m_params=m_params, imbalance=imbalance)\n",
    "    print(\"==================== Training End ====================\")\n",
    "\n",
    "    if roc:\n",
    "        # roc plot\n",
    "        print(\"Training ROC ====================\")\n",
    "        best_train = plot_roc(est, train_x, train_y)\n",
    "        \n",
    "        print(\"Test ROC ====================\")\n",
    "        best_test = plot_roc(est, test_x, test_y)\n",
    "        \n",
    "        # predict\n",
    "        train_yhat = est.predict_proba(train_x)[:, 1]\n",
    "        train_yhat = np.where(train_yhat>=best_train, 1, 0)\n",
    "    \n",
    "        test_yhat = est.predict_proba(test_x)[:, 1]\n",
    "        test_yhat = np.where(test_yhat>=best_train, 1, 0)\n",
    "    else:\n",
    "        best_train = 0.5\n",
    "        train_yhat = est.predict(train_x)\n",
    "        test_yhat = est.predict(test_x)\n",
    "\n",
    "    \n",
    "    print(\"==================== Model info ====================\")    \n",
    "    print('Best Model: ' + cv_report[cv_report['rank_test_score']=='all']['model'][0])\n",
    "        \n",
    "    # plot importance\n",
    "    plot_importance(est, train_x)\n",
    "        \n",
    "    # train report\n",
    "    print(\"Training Data: \")\n",
    "    model_info(train_y, train_yhat)\n",
    "    print(classification_report(train_y, train_yhat))\n",
    "\n",
    "    # test data\n",
    "    print(\"Testing Data: \")\n",
    "    model_info(test_y, test_yhat)\n",
    "    print(classification_report(test_y, test_yhat))\n",
    "\n",
    "    return est, cv_report, train_yhat, best_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "amber-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_process(df, model_params):\n",
    "    # to numeric\n",
    "    print('to Numeric:')\n",
    "    for i in model_params['numeric_col']:\n",
    "        df[i] = pd.to_numeric(df[i])\n",
    "        print(i + ' ok')\n",
    "\n",
    "    # to ordinal\n",
    "    print('to Ordinal:')\n",
    "    for i in model_params['ordinal']:\n",
    "        df[i] = df[i].astype(str)\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(df[i])\n",
    "        df[i] = le.transform(df[i])\n",
    "        print(i + ' ok')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5c4dc5-dac6-492d-ab5e-9724ff93e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: merge dtid \n",
    "dt = pd.read_csv(f\"/home/jovyan/work/riskModel/a0001/copy_0822/prepare_data/training.csv\")\n",
    "dt = dt[dt.columns[~dt.columns.isin(['id','AGE','index_date','AGE_n_last','SUICIDEREASON_last',\n",
    "                                     'BEHAVIOR_CD_last'])]]\n",
    "dt['event'] = dt['event'].map({'case':1,'control':0})\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "dt[dt.columns] = dt[dt.columns].apply(encoder.fit_transform)\n",
    "dt = dt.apply(lambda x: x.astype('category'))\n",
    "\n",
    "print(dt.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "67e4aee8-002d-4cb8-a054-6d13db27541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dt[(dt['train_test']==1)][dt.columns[~dt.columns.isin([\"event\",'train_test','n'])]]\n",
    "y_train = dt[dt['train_test']==1]['event']\n",
    "x_test = dt[(dt['train_test']==0)][dt.columns[~dt.columns.isin([\"event\",'train_test','n'])]]\n",
    "y_test = dt[dt['train_test']==0]['event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6fdd48-44c7-4636-abb6-e7e46b8375c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "est, cv_report, train_yhat, best_train = model_process(train_x=x_train,\n",
    "                                                       train_y=y_train,\n",
    "                                                       test_x=x_test,\n",
    "                                                       test_y=y_test,\n",
    "                                                       m=['tree', 'rf'],\n",
    "                                                       imbalance=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
